<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OCR Text Reader with Image Overlay</title>
    <!-- Tesseract.js for OCR -->
    <script src='https://cdnjs.cloudflare.com/ajax/libs/tesseract.js/4.1.1/tesseract.min.js'></script>
    <style>
        /* General Setup */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #434343 0%, #000000 100%);
            min-height: 100vh;
            padding: 20px;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        
        .container {
            background: #fff;
            border-radius: 12px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.4);
            padding: 30px;
            max-width: 800px;
            width: 100%;
        }
        
        h1 {
            color: #1e3a8a;
            margin-bottom: 20px;
            text-align: center;
            font-size: 2.2em;
        }

        /* Upload Area */
        #uploadArea {
            border: 2px dashed #93c5fd;
            border-radius: 8px;
            padding: 40px 20px;
            text-align: center;
            cursor: pointer;
            transition: background-color 0.2s, border-color 0.2s;
            color: #3b82f6;
            margin-bottom: 20px;
        }
        
        #uploadArea:hover, #uploadArea.dragover {
            background-color: #eff6ff;
            border-color: #2563eb;
        }
        
        #fileInput {
            display: none;
        }

        /* Status & Progress */
        #status {
            text-align: center;
            margin-bottom: 15px;
            font-weight: 500;
        }
        
        .processing { color: #f97316; }
        .success { color: #10b981; }
        .error { color: #ef4444; }

        #progressBar {
            height: 8px;
            background-color: #e5e7eb;
            border-radius: 4px;
            margin-bottom: 20px;
            overflow: hidden;
            display: none;
        }
        
        #progressBar.visible { display: block; }

        #progressFill {
            height: 100%;
            background-color: #3b82f6;
            width: 0%;
            transition: width 0.3s;
        }

        /* --- Image and Overlay Container --- */
        #imageContainer {
            position: relative;
            max-width: 100%;
            margin: 0 auto 20px auto;
            border-radius: 8px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            display: none; /* Hidden until image is loaded */
            line-height: 1; /* Essential for accurate word placement */
        }

        /* Base Image */
        #preview {
            display: block;
            width: 100%;
            height: auto;
            border-radius: 8px;
        }
        
        /* Text Overlay Layer */
        #textOverlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            font-size: 1px; /* Ensure no default font sizing interferes with layout */
            overflow: hidden;
            pointer-events: none; /* Default: ignore clicks */
        }
        
        #textOverlay.active {
            pointer-events: auto; /* Enable clicks when OCR is done */
        }

        /* Overlay Word Styles (Absolutely Positioned) */
        .overlay-word {
            position: absolute;
            line-height: 1.0;
            font-weight: normal; 
            white-space: nowrap; 
            text-align: center;
            /* Initial state: semi-transparent, not highlighted */
            background-color: transparent; 
            color: #1f2937; /* Dark text color */
            opacity: 0.15; /* 15% opacity when idle */
            cursor: pointer;
            transition: opacity 0.2s, background-color 0.2s;
            border-radius: 2px;
            z-index: 10;
        }

        /* Highlighted State (when read aloud) */
        .overlay-word.highlight {
            background-color: #fde047; /* Bright yellow highlight */
            opacity: 1.0; /* 100% opacity when highlighted */
            font-weight: 700;
        }

        /* Controls */
        #controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 20px;
            display: none; 
        }
        
        #controls.visible { display: flex; }

        .btn {
            padding: 10px 20px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-weight: 600;
            transition: transform 0.1s, box-shadow 0.1s;
            pointer-events: none;
            opacity: 0.6;
        }
        
        .btn.active {
            pointer-events: auto;
            opacity: 1;
        }

        .btn:active {
            transform: translateY(1px);
        }

        #readBtn { background-color: #34d399; color: white; }
        #readBtn:hover { background-color: #10b981; box-shadow: 0 4px 10px rgba(52, 211, 153, 0.5); }
        
        #pauseBtn, #stopBtn { background-color: #fca5a5; color: #7f1d1d; }
        #pauseBtn:hover, #stopBtn:hover { background-color: #f87171; box-shadow: 0 4px 10px rgba(252, 165, 165, 0.5); }
        
        /* Responsive adjustments */
        @media (max-width: 600px) {
            .container {
                padding: 20px;
            }
            h1 {
                font-size: 1.8em;
            }
            #uploadArea {
                padding: 30px 15px;
            }
            #controls {
                flex-direction: column;
                gap: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Visual OCR & Read Aloud Tool</h1>
        <p style="text-align: center;">Upload an image to extract text and have it read aloud. This tool works best with image files containing only text.</p>
        <br>
        <div id="uploadArea">
            <input type="file" id="fileInput" accept="image/*">
            <p>Drag & Drop an Image or Click to Upload</p>
            <p style="font-size: 0.8em; color: #9ca3af;">(Supported formats: JPG, PNG)</p>
        </div>

        <div id="imageContainer">
            <img id="preview" alt="Image Preview">
            <div id="textOverlay"></div>
        </div>

        <div id="status" class="idle">Waiting for Speech API to load...</div>

        <div id="progressBar">
            <div id="progressFill"></div>
        </div>
        
        <div id="controls">
            <button id="readBtn" class="btn">▶️ Read Aloud</button>
            <button id="pauseBtn" class="btn" style="display:none;">⏸️ Pause</button>
            <button id="stopBtn" class="btn">⏹️ Stop</button>
        </div>

        <!-- NOTE: textOutput is now hidden and used only for character index alignment data -->
        <div id="textOutput" style="display:none;"></div> 
    </div>

    <script>
        // --- 1. UI Element References ---
        const ui = {
            fileInput: document.getElementById('fileInput'),
            uploadArea: document.getElementById('uploadArea'),
            imageContainer: document.getElementById('imageContainer'),
            preview: document.getElementById('preview'),
            textOverlay: document.getElementById('textOverlay'),
            status: document.getElementById('status'),
            controls: document.getElementById('controls'),
            readBtn: document.getElementById('readBtn'),
            pauseBtn: document.getElementById('pauseBtn'),
            stopBtn: document.getElementById('stopBtn'),
            progressBar: document.getElementById('progressBar'),
            progressFill: document.getElementById('progressFill'),
        };

        // --- 2. State Management & Initialization ---
        let extractedText = '';
        let wordData = []; // [{ text: 'word', bbox: [x1, y1, x2, y2], charIndex: 0, element: spanElement }]
        let isPaused = false;
        let selectedVoice = null;
        let originalImageDimensions = { width: 0, height: 0 };
        
        // Internal state for word element lookup (map charIndex to element)
        let wordElementMap = new Map(); 

        // Ensure voices are loaded before attempting to speak
        function loadVoices() {
            const voices = window.speechSynthesis.getVoices();
            if (voices.length === 0) {
                window.speechSynthesis.onvoiceschanged = () => {
                    selectedVoice = window.speechSynthesis.getVoices().find(v => v.lang.startsWith('en')) || window.speechSynthesis.getVoices()[0];
                    if (extractedText.length === 0) {
                        ui.status.textContent = 'Speech API ready. Waiting for image upload...';
                        ui.status.className = 'idle';
                    }
                };
            } else {
                selectedVoice = voices.find(v => v.lang.startsWith('en')) || voices[0];
                if (extractedText.length === 0) {
                    ui.status.textContent = 'Speech API ready. Waiting for image upload...';
                    ui.status.className = 'idle';
                }
            }
        }
        loadVoices();


        // --- 3. Core Utility Functions ---

        /** Clears all word highlights */
        function clearAllHighlights() {
            wordData.forEach(data => {
                if (data.element) {
                    data.element.classList.remove('highlight');
                }
            });
        }

        /** Highlights a specific word element based on its character index */
        function highlightWord(charIndex) {
            clearAllHighlights();
            const element = wordElementMap.get(charIndex);
            if (element) {
                element.classList.add('highlight');
                // We no longer scroll the overlay, as it sits on the image.
                // If the image itself is too big for the viewport, the container handles scroll.
            }
        }
        
        /** * Parses the Tesseract HOCR output to extract word data with bounding boxes.
         * HOCR format uses pixel coordinates (x1 y1 x2 y2) relative to the original image.
         */
        function parseHOCR(hocrHtml) {
            const parser = new DOMParser();
            const doc = parser.parseFromString(hocrHtml, 'text/html');
            
            const words = [];
            const textNodes = doc.querySelectorAll('.ocrx_word');
            
            let runningCharIndex = 0;
            let fullText = '';
            
            textNodes.forEach(wordNode => {
                const text = wordNode.textContent;
                const title = wordNode.getAttribute('title');
                
                // Extract bounding box (bbox) from the title attribute
                // Example title: 'bbox 19 22 233 45; x_wconf 95'
                const bboxMatch = title ? title.match(/bbox (\d+) (\d+) (\d+) (\d+)/) : null;
                
                if (bboxMatch) {
                    const [x1, y1, x2, y2] = bboxMatch.slice(1).map(Number);
                    
                    // Add leading space if needed (simulating normal text flow)
                    if (fullText.length > 0 && text.length > 0) {
                        // Check if the current word is preceded by any whitespace in the raw HOCR structure (this is imperfect)
                        // A more robust way is just to add a space between words, but we rely on Tesseract's structure implicitly.
                        // For simplicity, we assume Tesseract naturally separates words. 
                        
                        // We use the word-by-word approach to build the text and character indices.
                        if (fullText.slice(-1) !== ' ' && fullText.length > 0) {
                            fullText += ' ';
                            runningCharIndex++;
                        }
                    }

                    words.push({
                        text: text,
                        bbox: [x1, y1, x2, y2],
                        charIndex: runningCharIndex,
                        element: null, // Will be populated later
                    });
                    
                    fullText += text;
                    runningCharIndex += text.length;
                }
            });
            
            // Tesseract's HOCR is often better than the pure text output for structure,
            // but we use this derived text for TTS coherence.
            extractedText = fullText.trim(); 
            wordData = words;
            
            return fullText;
        }

        /**
         * Creates and positions the overlay word spans based on scaled coordinates.
         * This function handles the visual part of the text.
         */
        function displayOverlayText() {
            ui.textOverlay.innerHTML = '';
            wordElementMap.clear();

            if (wordData.length === 0) return;

            // 1. Calculate Scaling Factor
            const previewWidth = ui.preview.offsetWidth;
            const originalWidth = originalImageDimensions.width;
            const scale = previewWidth / originalWidth;

            // 2. Create and Position Word Spans
            wordData.forEach(data => {
                const [x1, y1, x2, y2] = data.bbox;
                
                // Scale coordinates
                const left = x1 * scale;
                const top = y1 * scale;
                const width = (x2 - x1) * scale;
                const height = (y2 - y1) * scale;
                
                // Determine appropriate font size based on scaled height
                // We subtract a small buffer (e.g., 2px) to ensure the text fits within the box visually.
                const fontSize = Math.max(8, height - 2); 

                const wordSpan = document.createElement('span');
                wordSpan.className = 'overlay-word';
                wordSpan.textContent = data.text;
                
                // Set absolute positioning styles
                wordSpan.style.left = `${left}px`;
                wordSpan.style.top = `${top}px`;
                wordSpan.style.width = `${width}px`;
                wordSpan.style.height = `${height}px`;
                wordSpan.style.fontSize = `${fontSize}px`;
                
                // Data for TTS alignment and click functionality
                wordSpan.dataset.charIndex = data.charIndex;

                wordSpan.addEventListener('click', handleWordClick); 

                ui.textOverlay.appendChild(wordSpan);
                data.element = wordSpan; // Link the data object to the element
                wordElementMap.set(data.charIndex, wordSpan); // Map for quick highlight lookup
            });
            
            ui.textOverlay.classList.add('active'); // Enable clicks on the overlay
        }

        // --- 4. TTS Control Functions ---

        /** Stops any ongoing speech and cleans up UI */
        function stopSpeech() {
            window.speechSynthesis.cancel();
            clearAllHighlights();
            isPaused = false;
            ui.readBtn.style.display = 'inline-block';
            ui.pauseBtn.style.display = 'none';
            ui.pauseBtn.classList.remove('active'); 
            ui.pauseBtn.textContent = '⏸️ Pause'; 
        }

        /**
         * Starts a new speech utterance.
         */
        function startSpeech(text, startCharIndex, isSingleWord) {
            // 1. Immediately cancel any existing speech
            window.speechSynthesis.cancel(); 

            if (!selectedVoice) {
                ui.status.textContent = 'Error: No speech voices available.';
                ui.status.className = 'error';
                return;
            }

            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 1.0;
            utterance.voice = selectedVoice;
            
            let hasStarted = false; 
            
            // --- Event Handlers ---
            utterance.onstart = () => {
                hasStarted = true; 
                if (!isSingleWord) {
                    ui.readBtn.style.display = 'none';
                    ui.pauseBtn.style.display = 'inline-block';
                    ui.pauseBtn.classList.add('active'); 
                    ui.pauseBtn.textContent = '⏸️ Pause';
                    isPaused = false;
                }
                ui.status.textContent = 'Speaking...';
                ui.status.className = 'processing';
            };

            utterance.onboundary = (event) => {
                if (event.name === 'word') {
                    const absoluteCharIndex = startCharIndex + event.charIndex;
                    
                    // Look up the starting character index of the spoken word in our map
                    // Since TTS boundary events give the start of the word, we match directly
                    let wordCharIndex = -1;
                    for (const [charIndex, element] of wordElementMap.entries()) {
                         // Find the closest index match. Since TTS boundaries are accurate, 
                         // we check if the boundary event's index falls on the start of a word in our list.
                         if (charIndex === absoluteCharIndex) {
                            wordCharIndex = charIndex;
                            break;
                         }
                    }
                    highlightWord(wordCharIndex);
                }
            };

            utterance.onend = () => {
                if (extractedText.length > 0) {
                     ui.status.textContent = 'Finished reading text.';
                     ui.status.className = 'success';
                }
                stopSpeech(); 
            };
            
            // --- Error Handling ---
            utterance.onerror = (e) => {
                const isBenignEvent = !e.error && e.isTrusted;

                if (!isBenignEvent) {
                    console.error('Speech API Error:', e);
                }
                
                if (!hasStarted) { 
                    ui.status.textContent = 'Speech Error: Could not read text aloud. The browser queue may be locked.';
                    ui.status.className = 'error';
                    stopSpeech();
                }
            };
            
            // FIX: Active Speaking Check Polling
            function checkQueueAndSpeak(utterance) {
                if (window.speechSynthesis.speaking) {
                    setTimeout(() => checkQueueAndSpeak(utterance), 50);
                } else {
                    window.speechSynthesis.speak(utterance);
                }
            }
            
            checkQueueAndSpeak(utterance);
        }

        // --- 5. OCR and Display Logic (Refactored) ---

        async function performOCR(imageData) {
            stopSpeech(); 
            ui.status.textContent = 'Processing image... This may take a moment.';
            ui.status.className = 'processing';
            ui.progressBar.classList.add('visible');
            ui.controls.classList.remove('visible');
            ui.readBtn.classList.remove('active'); 
            ui.stopBtn.classList.remove('active');
            ui.textOverlay.classList.remove('active');
            
            try {
                const worker = await Tesseract.createWorker({
                    logger: (m) => {
                        if (m.status === 'recognizing text') {
                            const progress = Math.round(m.progress * 100);
                            ui.progressFill.style.width = progress + '%';
                            ui.status.textContent = `Processing image... ${progress}%`;
                        }
                    }
                });

                await worker.loadLanguage('eng');
                await worker.initialize('eng');
                
                // CRITICAL CHANGE: Request HOCR output for bounding boxes
                const { data: { hocr } } = await worker.recognize(imageData, { text: true, hocr: true });
                await worker.terminate();

                // Get original image dimensions from the preview element
                originalImageDimensions.width = ui.preview.naturalWidth;
                originalImageDimensions.height = ui.preview.naturalHeight;

                // Parse the HOCR data and populate wordData state
                const fullText = parseHOCR(hocr);
                extractedText = fullText.trim();
                
                if (extractedText.length > 0) {
                    // Display the absolutely positioned overlay text
                    displayOverlayText();
                    
                    ui.controls.classList.add('visible');
                    ui.readBtn.classList.add('active'); 
                    ui.stopBtn.classList.add('active');
                    ui.status.textContent = 'Text overlay ready! Click "Read Aloud" or click a word on the image to start.';
                    ui.status.className = 'success';
                } else {
                    ui.status.textContent = 'No text found in the image. Try a clearer photo.';
                    ui.status.className = 'error';
                }
                
                ui.progressBar.classList.remove('visible');
                ui.progressFill.style.width = '0%';
            } catch (error) {
                ui.status.textContent = 'OCR Error: ' + error.message;
                ui.status.className = 'error';
                ui.progressBar.classList.remove('visible');
            }
        }
        
        function handleFile(file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                ui.preview.onload = () => {
                    // Once the image is loaded in the DOM, we can run OCR
                    ui.imageContainer.style.display = 'block';
                    performOCR(e.target.result);
                    // Rerun alignment on window resize
                    window.onresize = displayOverlayText;
                };
                ui.preview.src = e.target.result;
            };
            reader.readAsDataURL(file);
        }

        // --- 6. Event Listeners ---

        // File/Drag and Drop Handlers (unchanged)
        ui.uploadArea.addEventListener('click', () => ui.fileInput.click());
        ui.uploadArea.addEventListener('dragover', (e) => {
            e.preventDefault();
            ui.uploadArea.classList.add('dragover');
        });
        ui.uploadArea.addEventListener('dragleave', () => {
            ui.uploadArea.classList.remove('dragover');
        });
        ui.uploadArea.addEventListener('drop', (e) => {
            e.preventDefault();
            ui.uploadArea.classList.remove('dragover');
            const file = e.dataTransfer.files[0];
            if (file && file.type.startsWith('image/')) {
                handleFile(file);
            }
        });
        ui.fileInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) {
                handleFile(file);
            }
        });

        // TTS Control Button Handlers
        ui.readBtn.addEventListener('click', () => {
            if (extractedText) {
                startSpeech(extractedText, 0, false);
            }
        });

        ui.pauseBtn.addEventListener('click', () => {
            if (window.speechSynthesis.speaking) {
                if (isPaused) {
                    window.speechSynthesis.resume();
                    ui.pauseBtn.textContent = '⏸️ Pause';
                    isPaused = false;
                } else {
                    window.speechSynthesis.pause();
                    ui.pauseBtn.textContent = '▶️ Resume';
                    isPaused = true;
                }
            }
        });

        ui.stopBtn.addEventListener('click', stopSpeech);


        // Word Click Handler (Click-to-start or Single-word repeat)
        function handleWordClick(event) {
            const clickedWordSpan = event.target;
            // Only proceed if the clicked element is an overlay word
            if (!clickedWordSpan.classList.contains('overlay-word')) return;

            const startIndex = parseInt(clickedWordSpan.dataset.charIndex, 10);
            const wordText = clickedWordSpan.textContent.trim(); 
            
            // To ensure reading starts from the actual beginning of the word in the full text,
            // we need to include the preceding space if one exists in the full extractedText.
            // However, for simplicity and alignment with TTS boundaries, we stick to the 
            // text substring approach below, which is safer.

            if (window.speechSynthesis.paused || !window.speechSynthesis.speaking) {
                // Single-word repeat mode (when stopped or paused)
                startSpeech(wordText, startIndex, true);
            } else {
                // Read from this point onwards (when currently speaking)
                // Note: We include the rest of the text, trimmed of leading spaces.
                let newText = extractedText.substring(startIndex).trimStart();
                
                // Find the new absolute starting index for the TTS boundary calculation
                // (This accounts for any spaces trimmed from the beginning)
                const actualStartIndex = extractedText.indexOf(newText, startIndex);
                
                startSpeech(newText, actualStartIndex, false);
            }
        }
    </script>
</body>
</html>
